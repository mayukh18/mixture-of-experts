{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a75157",
   "metadata": {},
   "source": [
    "### Reference Paper\n",
    "\n",
    "VOTING-BASED ENSEMBLE MODEL FOR NETWORK ANOMALY DETECTION [https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414532]\n",
    "\n",
    "1. Hard Voting (Majority voting) : Highest number of class predicted by all experts\n",
    "\n",
    "2. Soft Voting (Mean Logits): Highest value of probablity after summing logits over all experts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8047d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "985dada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseDispatcher(object):\n",
    "    \"\"\"Helper for implementing a mixture of experts.\n",
    "    The purpose of this class is to create input minibatches for the\n",
    "    experts and to combine the results of the experts to form a unified\n",
    "    output tensor.\n",
    "    There are two functions:\n",
    "    dispatch - take an input Tensor and create input Tensors for each expert.\n",
    "    combine - take output Tensors from each expert and form a combined output\n",
    "      Tensor.  Outputs from different experts for the same batch element are\n",
    "      summed together, weighted by the provided \"gates\".\n",
    "    The class is initialized with a \"gates\" Tensor, which specifies which\n",
    "    batch elements go to which experts, and the weights to use when combining\n",
    "    the outputs.  Batch element b is sent to expert e iff gates[b, e] != 0.\n",
    "    The inputs and outputs are all two-dimensional [batch, depth].\n",
    "    Caller is responsible for collapsing additional dimensions prior to\n",
    "    calling this class and reshaping the output to the original shape.\n",
    "    See common_layers.reshape_like().\n",
    "    Example use:\n",
    "    gates: a float32 `Tensor` with shape `[batch_size, num_experts]`\n",
    "    inputs: a float32 `Tensor` with shape `[batch_size, input_size]`\n",
    "    experts: a list of length `num_experts` containing sub-networks.\n",
    "    dispatcher = SparseDispatcher(num_experts, gates)\n",
    "    expert_inputs = dispatcher.dispatch(inputs)\n",
    "    expert_outputs = [experts[i](expert_inputs[i]) for i in range(num_experts)]\n",
    "    outputs = dispatcher.combine(expert_outputs)\n",
    "    The preceding code sets the output for a particular example b to:\n",
    "    output[b] = Sum_i(gates[b, i] * experts[i](inputs[b]))\n",
    "    This class takes advantage of sparsity in the gate matrix by including in the\n",
    "    `Tensor`s for expert i only the batch elements for which `gates[b, i] > 0`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_experts, gates):\n",
    "        \"\"\"Create a SparseDispatcher.\"\"\"\n",
    "\n",
    "        self._gates = gates\n",
    "        self._num_experts = num_experts\n",
    "        # sort experts\n",
    "        sorted_experts, index_sorted_experts = torch.sort(torch.nonzero(gates), dim=0)\n",
    "        # drop indices\n",
    "        _, self._expert_index = sorted_experts.split(1, dim=1)\n",
    "        # get according batch index for each expert\n",
    "        self._batch_index = torch.nonzero(gates)[index_sorted_experts[:, 1], 0]\n",
    "        # calculate num samples that each expert gets\n",
    "        self._part_sizes = (gates > 0).sum(0).tolist()\n",
    "        # expand gates to match with self._batch_index\n",
    "        gates_exp = gates[self._batch_index.flatten()]\n",
    "        self._nonzero_gates = torch.gather(gates_exp, 1, self._expert_index)\n",
    "\n",
    "    def dispatch(self, inp):\n",
    "        \"\"\"Create one input Tensor for each expert.\n",
    "        The `Tensor` for a expert `i` contains the slices of `inp` corresponding\n",
    "        to the batch elements `b` where `gates[b, i] > 0`.\n",
    "        Args:\n",
    "          inp: a `Tensor` of shape \"[batch_size, <extra_input_dims>]`\n",
    "        Returns:\n",
    "          a list of `num_experts` `Tensor`s with shapes\n",
    "            `[expert_batch_size_i, <extra_input_dims>]`.\n",
    "        \"\"\"\n",
    "\n",
    "        # assigns samples to experts whose gate is nonzero\n",
    "\n",
    "        # expand according to batch index so we can just split by _part_sizes\n",
    "        inp_exp = inp[self._batch_index].squeeze(1)\n",
    "        return torch.split(inp_exp, self._part_sizes, dim=0)\n",
    "\n",
    "    def combine(self, expert_out, multiply_by_gates=True):\n",
    "        \"\"\"Sum together the expert output, weighted by the gates.\n",
    "        The slice corresponding to a particular batch element `b` is computed\n",
    "        as the sum over all experts `i` of the expert output, weighted by the\n",
    "        corresponding gate values.  If `multiply_by_gates` is set to False, the\n",
    "        gate values are ignored.\n",
    "        Args:\n",
    "          expert_out: a list of `num_experts` `Tensor`s, each with shape\n",
    "            `[expert_batch_size_i, <extra_output_dims>]`.\n",
    "          multiply_by_gates: a boolean\n",
    "        Returns:\n",
    "          a `Tensor` with shape `[batch_size, <extra_output_dims>]`.\n",
    "        \"\"\"\n",
    "        # apply exp to expert outputs, so we are not longer in log space\n",
    "        stitched = torch.cat(expert_out, 0).exp()\n",
    "\n",
    "        if multiply_by_gates:\n",
    "            stitched = stitched.mul(self._nonzero_gates)\n",
    "        zeros = torch.zeros(self._gates.size(0), expert_out[-1].size(1), requires_grad=True, device=stitched.device)\n",
    "        # combine samples that have been processed by the same k experts\n",
    "        combined = zeros.index_add(0, self._batch_index, stitched.float())\n",
    "        # add eps to all zero values in order to avoid nans when going back to log space\n",
    "        combined[combined == 0] = np.finfo(float).eps\n",
    "        # back to log space\n",
    "        return combined.log()\n",
    "\n",
    "    def expert_to_gates(self):\n",
    "        \"\"\"Gate values corresponding to the examples in the per-expert `Tensor`s.\n",
    "        Returns:\n",
    "          a list of `num_experts` one-dimensional `Tensor`s with type `tf.float32`\n",
    "              and shapes `[expert_batch_size_i]`\n",
    "        \"\"\"\n",
    "        # split nonzero gates for each expert\n",
    "        return torch.split(self._nonzero_gates, self._part_sizes, dim=0)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.soft = nn.Softmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.soft(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "085098b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoE(nn.Module):\n",
    "\n",
    "    \"\"\"Call a Sparsely gated mixture of experts layer with 1-layer Feed-Forward networks as experts.\n",
    "    Args:\n",
    "    input_size: integer - size of the input\n",
    "    output_size: integer - size of the input\n",
    "    num_experts: an integer - number of experts\n",
    "    hidden_size: an integer - hidden size of the experts\n",
    "    noisy_gating: a boolean\n",
    "    k: an integer - how many experts to use for each batch element\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size, num_experts, hidden_size, noisy_gating=True, k=4):\n",
    "        super(MoE, self).__init__()\n",
    "        self.noisy_gating = noisy_gating\n",
    "        self.num_experts = num_experts\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.k = k\n",
    "        # instantiate experts\n",
    "        self.experts = nn.ModuleList([MLP(self.input_size, self.output_size, self.hidden_size) for i in range(self.num_experts)])\n",
    "        self.w_gate = nn.Parameter(torch.zeros(input_size, num_experts), requires_grad=True)\n",
    "        self.w_noise = nn.Parameter(torch.zeros(input_size, num_experts), requires_grad=True)\n",
    "\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        self.register_buffer(\"mean\", torch.tensor([0.0]))\n",
    "        self.register_buffer(\"std\", torch.tensor([1.0]))\n",
    "        assert(self.k <= self.num_experts)\n",
    "\n",
    "    def cv_squared(self, x):\n",
    "        \"\"\"The squared coefficient of variation of a sample.\n",
    "        Useful as a loss to encourage a positive distribution to be more uniform.\n",
    "        Epsilons added for numerical stability.\n",
    "        Returns 0 for an empty Tensor.\n",
    "        Args:\n",
    "        x: a `Tensor`.\n",
    "        Returns:\n",
    "        a `Scalar`.\n",
    "        \"\"\"\n",
    "        eps = 1e-10\n",
    "        # if only num_experts = 1\n",
    "\n",
    "        if x.shape[0] == 1:\n",
    "            return torch.tensor([0], device=x.device, dtype=x.dtype)\n",
    "        return x.float().var() / (x.float().mean()**2 + eps)\n",
    "\n",
    "    def _gates_to_load(self, gates):\n",
    "        \"\"\"Compute the true load per expert, given the gates.\n",
    "        The load is the number of examples for which the corresponding gate is >0.\n",
    "        Args:\n",
    "        gates: a `Tensor` of shape [batch_size, n]\n",
    "        Returns:\n",
    "        a float32 `Tensor` of shape [n]\n",
    "        \"\"\"\n",
    "        return (gates > 0).sum(0)\n",
    "\n",
    "    def _prob_in_top_k(self, clean_values, noisy_values, noise_stddev, noisy_top_values):\n",
    "        \"\"\"Helper function to NoisyTopKGating.\n",
    "        Computes the probability that value is in top k, given different random noise.\n",
    "        This gives us a way of backpropagating from a loss that balances the number\n",
    "        of times each expert is in the top k experts per example.\n",
    "        In the case of no noise, pass in None for noise_stddev, and the result will\n",
    "        not be differentiable.\n",
    "        Args:\n",
    "        clean_values: a `Tensor` of shape [batch, n].\n",
    "        noisy_values: a `Tensor` of shape [batch, n].  Equal to clean values plus\n",
    "          normally distributed noise with standard deviation noise_stddev.\n",
    "        noise_stddev: a `Tensor` of shape [batch, n], or None\n",
    "        noisy_top_values: a `Tensor` of shape [batch, m].\n",
    "           \"values\" Output of tf.top_k(noisy_top_values, m).  m >= k+1\n",
    "        Returns:\n",
    "        a `Tensor` of shape [batch, n].\n",
    "        \"\"\"\n",
    "        batch = clean_values.size(0)\n",
    "        m = noisy_top_values.size(1)\n",
    "        top_values_flat = noisy_top_values.flatten()\n",
    "\n",
    "        threshold_positions_if_in = torch.arange(batch, device=clean_values.device) * m + self.k\n",
    "        threshold_if_in = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_in), 1)\n",
    "        is_in = torch.gt(noisy_values, threshold_if_in)\n",
    "        threshold_positions_if_out = threshold_positions_if_in - 1\n",
    "        threshold_if_out = torch.unsqueeze(torch.gather(top_values_flat, 0, threshold_positions_if_out), 1)\n",
    "        # is each value currently in the top k.\n",
    "        normal = Normal(self.mean, self.std)\n",
    "        prob_if_in = normal.cdf((clean_values - threshold_if_in)/noise_stddev)\n",
    "        prob_if_out = normal.cdf((clean_values - threshold_if_out)/noise_stddev)\n",
    "        prob = torch.where(is_in, prob_if_in, prob_if_out)\n",
    "        return prob\n",
    "\n",
    "    def noisy_top_k_gating(self, x, train, noise_epsilon=1e-2):\n",
    "        \"\"\"Noisy top-k gating.\n",
    "          See paper: https://arxiv.org/abs/1701.06538.\n",
    "          Args:\n",
    "            x: input Tensor with shape [batch_size, input_size]\n",
    "            train: a boolean - we only add noise at training time.\n",
    "            noise_epsilon: a float\n",
    "          Returns:\n",
    "            gates: a Tensor with shape [batch_size, num_experts]\n",
    "            load: a Tensor with shape [num_experts]\n",
    "        \"\"\"\n",
    "        clean_logits = x @ self.w_gate\n",
    "        if self.noisy_gating and train:\n",
    "            raw_noise_stddev = x @ self.w_noise\n",
    "            noise_stddev = ((self.softplus(raw_noise_stddev) + noise_epsilon))\n",
    "            noisy_logits = clean_logits + (torch.randn_like(clean_logits) * noise_stddev)\n",
    "            logits = noisy_logits\n",
    "        else:\n",
    "            logits = clean_logits\n",
    "\n",
    "        # calculate topk + 1 that will be needed for the noisy gates\n",
    "        top_logits, top_indices = logits.topk(min(self.k + 1, self.num_experts), dim=1)\n",
    "        top_k_logits = top_logits[:, :self.k]\n",
    "        top_k_indices = top_indices[:, :self.k]\n",
    "        top_k_gates = self.softmax(top_k_logits)\n",
    "\n",
    "        zeros = torch.zeros_like(logits, requires_grad=True)\n",
    "        gates = zeros.scatter(1, top_k_indices, top_k_gates)\n",
    "\n",
    "        if self.noisy_gating and self.k < self.num_experts and train:\n",
    "            load = (self._prob_in_top_k(clean_logits, noisy_logits, noise_stddev, top_logits)).sum(0)\n",
    "        else:\n",
    "            load = self._gates_to_load(gates)\n",
    "        return gates, load\n",
    "\n",
    "    def forward(self, x, loss_coef=1e-2):\n",
    "        \"\"\"Args:\n",
    "        x: tensor shape [batch_size, input_size]\n",
    "        train: a boolean scalar.\n",
    "        loss_coef: a scalar - multiplier on load-balancing losses\n",
    "\n",
    "        Returns:\n",
    "        y: a tensor with shape [batch_size, output_size].\n",
    "        extra_training_loss: a scalar.  This should be added into the overall\n",
    "        training loss of the model.  The backpropagation of this loss\n",
    "        encourages all experts to be approximately equally used across a batch.\n",
    "        \"\"\"\n",
    "        gates, load = self.noisy_top_k_gating(x, self.training)\n",
    "        # calculate importance loss\n",
    "        importance = gates.sum(0)\n",
    "        #\n",
    "        loss = self.cv_squared(importance) + self.cv_squared(load)\n",
    "        loss *= loss_coef\n",
    "\n",
    "        dispatcher = SparseDispatcher(self.num_experts, gates)\n",
    "        expert_inputs = dispatcher.dispatch(x)\n",
    "        gates = dispatcher.expert_to_gates()\n",
    "        expert_outputs = [self.experts[i](expert_inputs[i]) for i in range(self.num_experts)]\n",
    "        y = dispatcher.combine(expert_outputs)\n",
    "        return y, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "66cd9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelExperts(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_experts, hidden_size, method):\n",
    "        super(ParallelExperts, self).__init__()\n",
    "        self.method = method\n",
    "        self.num_experts = num_experts\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # instantiate experts\n",
    "        self.experts = nn.ModuleList([MLP(self.input_size, self.output_size, self.hidden_size) for i in range(self.num_experts)])\n",
    "\n",
    "        self.final = nn.Linear(self.output_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [self.experts[i](x) for i in range(self.num_experts)]\n",
    "        outputs = torch.stack([self.final(out) for out in outputs], dim=2)\n",
    "        if self.training == True:\n",
    "            return torch.mean(outputs, dim=-1), 0\n",
    "        else:\n",
    "            if self.method == 'Hard - Voting':\n",
    "                per_expert = torch.argmax(outputs, dim=-1)\n",
    "                return torch.mode(per_expert, dim=1).values\n",
    "            elif self.method == 'Soft - Voting':\n",
    "                return torch.mean(outputs, dim=-1), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b9d95480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ParallelExperts(\n",
       "  (experts): ModuleList(\n",
       "    (0): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "    (1): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "    (2): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "    (3): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "    (4): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "    (5): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "    (6): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "    (7): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "    (8): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "    (9): MLP(\n",
       "      (fc1): Linear(in_features=3072, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (soft): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       "  (final): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "# from torchsummary import summary\n",
    "# from variations import ParallelExperts, CascadedExperts\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "# net = MoE(input_size=3072, output_size=10, num_experts=10, hidden_size=256, noisy_gating=True, k=4)\n",
    "# net = net.to(device)\n",
    "# # print(summary(net, (3*32*32,)))\n",
    "\n",
    "method = 'Hard - Voting'\n",
    "\n",
    "net = ParallelExperts(input_size=3072, output_size=10, num_experts=10, hidden_size=256, method=method)\n",
    "net = net.to(device)\n",
    "# print(summary(net, (3*32*32,)))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e55ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 782/782 [01:07<00:00, 11.51it/s]\n",
      "100%|█████████████████████████████████████████| 782/782 [01:16<00:00, 10.25it/s]\n",
      "100%|█████████████████████████████████████████| 782/782 [01:05<00:00, 11.89it/s]\n",
      "100%|█████████████████████████████████████████| 782/782 [01:04<00:00, 12.07it/s]\n",
      "100%|████████████████████████████████████████▊| 779/782 [00:55<00:00, 16.65it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    for data in tqdm(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "        outputs, aux_loss = net(inputs)\n",
    "        #print(outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss = loss + aux_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 100 == 99:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 100))\n",
    "#             running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e554d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 157/157 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 20 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(testloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        if method == 'Soft - Voting':\n",
    "            outputs, _ = net(images.view(images.shape[0], -1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        elif method == 'Hard - Voting':\n",
    "            predicted = net(images.view(images.shape[0], -1))\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "# yields a test accuracy of around 34 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2af7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
